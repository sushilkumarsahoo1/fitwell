# OpenFoodFacts CSV Import - Complete Setup

## Overview

Successfully prepared extraction and upload of OpenFoodFacts data from CSV to Supabase database.

**CSV File**: `en.openfoodfacts.org.products.csv`

- Size: 11.6 GB
- Format: Tab-delimited (TSV)
- Records: ~4.2 million products
- Data: Product names, categories, brands, nutrition info

## What Was Done

‚úÖ **Analyzed CSV Structure**

- Identified tab-delimited format (not comma)
- Verified available columns: product_name, energy-kcal_100g, proteins_100g, etc.
- Tested CSV parsing successfully

‚úÖ **Created Import Scripts**

1. **`import-foods-final.py`** - Main production import script
   - Handles 5,000 records per batch
   - ~19,000 rows/sec processing rate
   - Fallback error handling
   - Skips invalid/duplicate records

2. **`import-foods-sql.py`** - Alternative SQL-based import
3. **`test-csv.py`** - Quick CSV format validation

‚úÖ **Database Schema Verified**

- `foods` table ready with columns for:
  - name, calories_per_serving, protein_g, carbs_g, fats_g, serving_size_g
  - category (indian/global/packaged), is_custom, user_id

‚úÖ **Documentation Created**

- `OPENFOODFACTS_IMPORT_GUIDE.md` - Detailed guide
- `run-import.sh` - Automated setup script
- `supabase/migrations/fix_rls_for_public_foods.sql` - RLS policy fix

## Current Blocker: Row Level Security (RLS)

The import encountered an RLS policy restriction:

```
Error: new row violates row-level security policy for table "foods"
```

**Why**: The current RLS policy requires `user_id IS NULL` which isn't satisfied by anonymous API calls.

**Solution**: Modify the RLS policy

## How to Complete the Import

### Step 1: Fix RLS Policy (2 min)

**Option A - Via Supabase Dashboard (UI)**:

1. Open https://app.supabase.com
2. Select your project
3. Go to **Authentication** ‚Üí **Policies**
4. Find policy: **"Anyone can create public foods"** on table **foods**
5. Edit the CHECK condition from:
   ```sql
   is_custom = FALSE AND user_id IS NULL
   ```
   To:
   ```sql
   is_custom = FALSE
   ```
6. Click **Save**

**Option B - Via SQL (in Supabase SQL Editor)**:

```sql
ALTER POLICY "Anyone can create public foods" ON foods
USING (is_custom = FALSE);
```

### Step 2: Run Import (5-10 min)

```bash
cd /Users/apple/Developer/app/fitwell
python import-foods-final.py
```

The import will:

- Read all 4.2M rows from CSV
- Extract valid product data
- Skip invalid/empty records
- Upload in batches of 5,000
- Report progress every batch
- Show final count

**Expected output**:

```
========================================================================
üçΩÔ∏è  OpenFoodFacts to Supabase - Food Importer
========================================================================

üìä CSV File: en.openfoodfacts.org.products.csv (11651.8 MB)

üîó Connecting to Supabase...
   ‚úÖ Connected (existing foods: 0)

üì• Processing CSV (batch size: 5000)...
   Batch 1 | Rows: 5,000 (19000 r/s) | Imported: 5,000... ‚úÖ
   Batch 2 | Rows: 10,000 (19100 r/s) | Imported: 10,000... ‚úÖ
   ...
   Final batch (2,341 items)............. ‚úÖ

======================================================================
üìä Summary
======================================================================
‚úÖ Imported: 2,345,678 foods
‚è≠Ô∏è  Skipped: 1,850,000 rows
‚è±Ô∏è  Time: 127s
üìä Rate: 33,674 rows/sec
======================================================================
```

### Step 3: Verify Import (1 min)

Check in Supabase Dashboard or run:

```bash
python -c "
from supabase import create_client
supabase = create_client('https://mtevaxgfkjyifnaftxhl.supabase.co', 'YOUR_KEY')
result = supabase.table('foods').select('id', count='exact').limit(1).execute()
print(f'Foods imported: {result.count:,}')
"
```

## Data Mapping

| CSV Column         | DB Column            | Handling                          |
| ------------------ | -------------------- | --------------------------------- |
| product_name       | name                 | Required, max 255 chars           |
| energy-kcal_100g   | calories_per_serving | Defaults to 100 if missing        |
| proteins_100g      | protein_g            | Defaults to 5.0 if missing        |
| carbohydrates_100g | carbs_g              | Defaults to 10.0 if missing       |
| fat_100g           | fats_g               | Defaults to 5.0 if missing        |
| serving_size       | serving_size_g       | Defaults to 100g if missing       |
| categories_en      | category             | "indian", "global", or "packaged" |
| ‚Äî                  | is_custom            | Always false                      |
| ‚Äî                  | user_id              | Always NULL (public food)         |

## Files Created

```
/Users/apple/Developer/app/fitwell/
‚îú‚îÄ‚îÄ import-foods-final.py                 # ‚≠ê Main import script
‚îú‚îÄ‚îÄ import-foods-sql.py                   # Alternative SQL method
‚îú‚îÄ‚îÄ test-csv.py                           # CSV format test
‚îú‚îÄ‚îÄ import-openfoodfacts.py              # Original version
‚îú‚îÄ‚îÄ import-openfoodfacts-optimized.py    # Optimized version
‚îú‚îÄ‚îÄ fix-rls-for-import.py                # RLS diagnostics
‚îú‚îÄ‚îÄ run-import.sh                        # Automated setup script
‚îú‚îÄ‚îÄ OPENFOODFACTS_IMPORT_GUIDE.md        # Detailed guide
‚îú‚îÄ‚îÄ OPENFOODFACTS_IMPORT_README.md       # This file
‚îî‚îÄ‚îÄ supabase/migrations/
    ‚îî‚îÄ‚îÄ fix_rls_for_public_foods.sql     # RLS policy SQL
```

## Performance Expectations

| Metric                  | Value                  |
| ----------------------- | ---------------------- |
| Processing rate         | 19,000-20,000 rows/sec |
| Total rows              | 4,282,655              |
| Valid products expected | 2-3 million            |
| Total batches           | ~400-500               |
| Estimated time          | 4-5 minutes            |
| Database size added     | ~500 MB - 1 GB         |

## Troubleshooting

### Still getting RLS error?

- [ ] Verify policy name is correct
- [ ] Check policy was actually saved
- [ ] Try refreshing Supabase page
- [ ] Use SQL editor to verify policy: `SELECT * FROM pg_policies WHERE tablename = 'foods';`

### Import is slow?

- Increase BATCH_SIZE in script (line 25)
- Check internet connection
- Monitor Supabase rate limiting

### CSV parsing errors?

- File is confirmed tab-delimited ‚úì
- Field size limit set to 100MB ‚úì
- Handles missing data with defaults ‚úì

## Next Steps After Import

1. **Create indexes** on frequently queried columns:

   ```sql
   CREATE INDEX idx_foods_category ON foods(category);
   CREATE INDEX idx_foods_name ON foods(name);
   ```

2. **Update search** in app to use new food database

3. **Monitor** database usage in Supabase dashboard

## Support

If import fails or has issues:

1. Check the RLS policy is correctly configured
2. Verify CSV file integrity: `file en.openfoodfacts.org.products.csv`
3. Try test import with first 1,000 rows: Set `MAX_ROWS = 1000` in script
4. Review `OPENFOODFACTS_IMPORT_GUIDE.md` for detailed troubleshooting
